{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Demo:  Document Clustering and Latent Semantic Analysis\n",
    "\n",
    "An important application of clustering is for sorting documents into groups.  In this demo, we will illustrate how to use the k-means algorithms for this task.  This example is taken mostly from one of the [sklearn examples](http://scikit-learn.org/stable/auto_examples/text/document_clustering.html).\n",
    "\n",
    "Through the demo, you will learn how to:\n",
    "* Compute the TF-IDF scores for documents in the corpus\n",
    "* Run k-means on the TF-IDF features to cluster documents\n",
    "* Run LSA (i.e., PCA) on the TF-IDF features to cluster documents\n",
    "* Run NMF to cluster documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "First, we load the standard packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [UseNet newsgroups](https://en.wikipedia.org/wiki/Usenet_newsgroup) were popular in the 1990s as online forums for discussing various topics.  Although they are not used much today for discussions, the UseNet data is widely-used in machine learning classes to demonstrate various text processing methods.  The `sklearn` package has the [20newsgroups](https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset) dataset, which has about 18000 posts on 20 topics.  It can be loaded via `fetch_20newsgroups`.  We will use only four of the 20 topics for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "load_all = False # load all categories?\n",
    "\n",
    "if load_all:\n",
    "    categories = None\n",
    "else:    \n",
    "    categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "    ]\n",
    "\n",
    "remove = ('headers', 'footers')\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories,\n",
    "                             remove = remove, shuffle=True, random_state=42)\n",
    "print(dataset.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset.target` is a vector of labels.  Let's print a few of them out.  Also, we can use the `np.unique` command to compute the number of unique labels, which should equal 4.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 3 1 1 2 2 2 0 1 2 3 2 0 3 3 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "labels = dataset.target # label vector \n",
    "print(labels[1:20])\n",
    "true_k = len(np.unique(labels)) # number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the number of data samples as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samp = 3387\n"
     ]
    }
   ],
   "source": [
    "print(\"num_samp = %d\" % labels.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset.data` contains the UseNet text data.  Each entry `dataset.data[i]` is a string corresponding to one post.  We can print an example as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post from comp.graphics:\n",
      "\n",
      "\n",
      "Hallo POV-Renderers !\n",
      "I've got a BocaX3 Card. Now I try to get POV displaying True Colors\n",
      "while rendering. I've tried most of the options and UNIVESA-Driver\n",
      "but what happens isn't correct.\n",
      "Can anybody help me ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_ind = 10  # Index of an example document\n",
    "data_ex = dataset.data[doc_ind]\n",
    "cat_ex  = dataset.target_names[labels[doc_ind]]\n",
    "print('Post from {0:s}:'.format(cat_ex))\n",
    "print()\n",
    "print(data_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing TF-IDF features\n",
    "\n",
    "Documents are text, but machine learning algorithms want numbers.  So, we need to extract numerical features from the documents.  One of the most popular methods is the so-called TF-IDF score.  First, we make a list of all (non-common) words in the corpus.  Each word is sometimes called a *term* or a *token*.  For each term `j` and document `i`, we compute the feature\n",
    "      \n",
    "    X[i,j] = TF-IDF score of term j in document i\n",
    "           = term_freq[i,j] * inverse_doc_freq[j]\n",
    "           \n",
    "where\n",
    "\n",
    "    term_freq[i,j]  = (#occurances of term j in doc i)/(#terms in doc i)  \n",
    "    inverse_doc_freq[j] = -log( #docs with term j / #docs in corpus )\n",
    "        \n",
    "In the data matrix `X`, each document `i` is represented by a vector `X[i,:]`.\n",
    "\n",
    "The data matrix `X` can be computed by a *vectorizer*.  Writing an efficient vectorizer is somewhat time-consuming.  Luckily, `sklearn` has very good routines to do this.  We first create a `TfidfVectorizer` object, and then use it to compute the TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 3387, n_features: 38777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english') # remove English stopwords\n",
    "\n",
    "X = vectorizer.fit_transform(dataset.data)\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display the terms with the highest TF-IDF scores in a document as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pov                  0.417453 \n",
      "hallo                0.314297 \n",
      "bocax3               0.314297 \n",
      "renderers            0.280154 \n",
      "univesa              0.273361 \n",
      "ve                   0.216374 \n",
      "displaying           0.215961 \n",
      "rendering            0.206597 \n",
      "options              0.205576 \n",
      "driver               0.199119 \n",
      "happens              0.187562 \n",
      "colors               0.184011 \n",
      "card                 0.177312 \n",
      "tried                0.163320 \n",
      "anybody              0.157071 \n",
      "correct              0.155991 \n",
      "isn                  0.132214 \n",
      "got                  0.127099 \n",
      "try                  0.126131 \n",
      "help                 0.125774 \n",
      "true                 0.124041 \n",
      "determining          0.000000 \n",
      "determinism          0.000000 \n",
      "determininant        0.000000 \n",
      "deterministic        0.000000 \n",
      "determnined          0.000000 \n",
      "determines           0.000000 \n",
      "deterrant            0.000000 \n",
      "determined           0.000000 \n",
      "detest               0.000000 \n"
     ]
    }
   ],
   "source": [
    "doc_ind = 10  # Index of an example document\n",
    "xi = X[doc_ind,:].todense()\n",
    "term_ind = xi.argsort()[:, ::-1]\n",
    "xi_sort = xi[0,term_ind]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(30):\n",
    "    term = terms[term_ind[0,i]]\n",
    "    tfidf = xi[0,term_ind[0,i]]\n",
    "    print('{0:20s} {1:f} '.format(term, tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running K-Means\n",
    "\n",
    "We now run k-means on the TF-IDF features in an attempt to cluster the documents.  First, we instantiate a `KMeans` object, and then we run the algorithm using the `fit` method.  We'll use the `++` initialization in an attempt to avoid local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 6461.628264313481\n",
      "Iteration 1, inertia 3306.315949575553\n",
      "Iteration 2, inertia 3296.9470173231202\n",
      "Iteration 3, inertia 3294.6351134679676\n",
      "Iteration 4, inertia 3293.6986887371013\n",
      "Iteration 5, inertia 3293.0801132179845\n",
      "Iteration 6, inertia 3292.685821975408\n",
      "Iteration 7, inertia 3292.4392047796755\n",
      "Iteration 8, inertia 3292.227604782814\n",
      "Iteration 9, inertia 3292.101241732236\n",
      "Iteration 10, inertia 3292.043203528274\n",
      "Iteration 11, inertia 3292.0009832615897\n",
      "Iteration 12, inertia 3291.952664071326\n",
      "Iteration 13, inertia 3291.913997506929\n",
      "Iteration 14, inertia 3291.8647964067823\n",
      "Iteration 15, inertia 3291.823791633892\n",
      "Iteration 16, inertia 3291.767778882536\n",
      "Iteration 17, inertia 3291.7208888575983\n",
      "Iteration 18, inertia 3291.696356271001\n",
      "Iteration 19, inertia 3291.685853667515\n",
      "Iteration 20, inertia 3291.679134499338\n",
      "Converged at iteration 20: strict convergence.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=4, n_init=1, random_state=1, verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1,\n",
    "                verbose=True, random_state=1)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense for the results of k-means, we print out the terms in each centroid with the 10 largest TF-IDF values.  You can see that K-means has found centroids that seem to correspond to the newsgroups topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroid 0: god jesus people objective sandvik don believe moral say morality\n",
      "Centroid 1: edu writes article com just think people don like know\n",
      "Centroid 2: graphics thanks image file files program format know images looking\n",
      "Centroid 3: space nasa shuttle launch orbit moon edu writes gov just\n"
     ]
    }
   ],
   "source": [
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(true_k):\n",
    "    print(\"Centroid %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of clusters to newsgroup categories\n",
    "\n",
    "To get a quantitative measure of how well k-means is matching the newsgroup topics, we create a sort of confusion matrix `C` where:\n",
    "\n",
    "`C[i,j] = ` the fraction of cluster `j` that came from newsgroup topic `i`.\n",
    "\n",
    "That is, the columns of the confusion matrix are normalized so that they sum to one.  If k-means was perfectly clustering according to the newsgroup topics, each column of `C` would contain a single value equal to one and the other values equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.548 0.342 0.004 0.002]\n",
      " [0.    0.165 0.938 0.008]\n",
      " [0.002 0.233 0.052 0.989]\n",
      " [0.45  0.26  0.006 0.002]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labelkm = km.labels_\n",
    "Cnorm = confusion_matrix(labels,labelkm,normalize='pred')\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(Cnorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret this confusion matrix, let's remember what the newsgroup categories were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the confusion matrix, we see that the last two clusters are dominated by a single newsgroup topic, comp.graphics and sci.space, respectively.  The first cluster is a mix between alt.atheism and talk.religion.misc, which makes sense because these two topics have a lot of overlap.  But the second cluster has a significant proportion of words from all four topics, so it doesn't seem to be well designed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now print an example of a document that came from a topic that is different from the most common topic in that cluster (i.e., a clustering error).  In particular, we'll print an example of an `alt.atheism` post in the cluster that is dominated by `comp.graphics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual newsgroup: alt.atheism\n",
      "Cluster index: 0\n",
      "\n",
      "sandvik@newton.apple.com (Kent Sandvik) writes:\n",
      "\n",
      ">>To borrow from philosophy, you don't truly understand the color red\n",
      ">>until you have seen it.\n",
      ">Not true, even if you have experienced the color red you still might\n",
      ">have a different interpretation of it.\n",
      "\n",
      "But, you wouldn't know what red *was*, and you certainly couldn't judge\n",
      "it subjectively.  And, objectivity is not applicable, since you are wanting\n",
      "to discuss the merits of red.\n"
     ]
    }
   ],
   "source": [
    "ind_true = 0 # index of alt.atheism\n",
    "ind_cluster = Cnorm[3,:].argmax() # cluster dominated by comp.graphics\n",
    "\n",
    "cat_true  = dataset.target_names[ind_true]\n",
    "print('Actual newsgroup: {0:s}'.format(cat_true))\n",
    "print('Cluster index: {0:d}'.format(ind_cluster))\n",
    "print()\n",
    "\n",
    "# find all documents with category=ind_true and cluster=ind_cluster\n",
    "I = np.where((labels==ind_true) & (labelkm==ind_cluster))[0]\n",
    "# choose one of these documents\n",
    "doc_ind = I[0]\n",
    "data_ex = dataset.data[doc_ind]\n",
    "# print the document\n",
    "print(data_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the above `alt.atheism` post, it is not surprising that it was grouped together with `comp.graphics` posts, because it frequently uses the terms `color` and `red`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Latent Semantic Analysis\n",
    "\n",
    "Another important tool in document analysis is [latent semantic analysis (LSA)](https://en.wikipedia.org/wiki/Latent_semantic_analysis).  In LSA, we basically perform PCA on the TF-IDF feature matrix `X`.  For this, we compute the SVD\n",
    "\n",
    "    X = U diag(S) Vt \n",
    "    \n",
    "where the rows of `Vt` contain the principal components (PCs) of `X`.  Note that if we define `A = U diag(S)` then `X = A Vt`.  \n",
    "\n",
    "It turns out that the TF-IDF matrix `X` is a sparse matrix:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, less than 1% of the entries in `X` are nonzero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity = 0.002404\n"
     ]
    }
   ],
   "source": [
    "h,w = X.get_shape()\n",
    "sparsity = X.count_nonzero()/(h*w)\n",
    "print(\"sparsity = %f\" % sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `X` is sparse, it is preferable to use the sparse version of the SVD, `svds`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse.linalg\n",
    "U,S,Vt = scipy.sparse.linalg.svds(X,k=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the singular values. We see that the first few singular values are significantly larger than the remaining singular values, suggesting that the term-document matrix `X` has an approximately low-rank structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feff45baa00>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(S[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the approximately low-rank structure of `X`, we can approximate it using a small number components (i.e., small `R`): \n",
    "\n",
    "     X[i,j] \\approx \\sum_{k=1}^R U[i,k] S[k] Vt[k,j]\n",
    "     \n",
    "There are two motivations for doing so:\n",
    "* Topic modeling:  One interpretation is that each principal component (PC) represents a *topic* in the corpus.  In other words, the rows `Vt[:,k]` of the `Vt` matrix can be linearly combined to approximate any row of `X`, i.e., any document vector `X[i,:]`, where each row of `Vt` (i.e., each PC) represents one topic.  \n",
    "* Topic modeling:  Likewise, the columns `U[:,k]` of the `U` matrix can be linearly combined to approximate any column of `X`, i.e., any term vector `X[:,j]`, where each column of `U` (i.e., each PC) represents one topic.\n",
    "* Document clustering: The `k`th entry of the row vector `U[i,:]` gives a value that measures the relationship between topic `k` and document `i`.  We could try to cluster the `i`th document by looking for the entry `k` with the largest magnitude, as we'll do below.\n",
    "* Word and document embeddings:  The row vector `U[i,:]` provides a low-dimensional summary of the `i`th document.  This is a useful quantity for many natural processing (NLP) methods.  This type of representation is closely related to an important topic of *word embeddings* and *document embeddings*.\n",
    "\n",
    "To get an idea of the words within each PC, we print the words for the largest-magnitude entries in the first few PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC 0: 3do rh craig post site number vesa terrorist days society\n",
      "PC 1: allah send anti test ye 3do faq actually dos posted\n",
      "PC 2: phigs program new psilink p00261 zip universe thing lot send\n",
      "PC 3: free polygon rle rh phigs read set siggraph convert different\n"
     ]
    }
   ],
   "source": [
    "Vt_sort = np.abs(Vt).argsort()[:, ::-1]\n",
    "for k in range(true_k):\n",
    "    print(\"PC %d:\" % k, end='')\n",
    "    for ind in Vt_sort[k, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, these principle components don't seem to match the newsgroup topics.\n",
    "\n",
    "To get a more quantitative view of LSA's clustering performance, let's try hard document clustering by assigning each document `i` to the topic index `k` that has the largest magnitude value in the PC vector `U[i,:]`.  After we compute hard labels for all documents, we compute the confusion matrix, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.205 0.248 0.252 0.24 ]\n",
      " [0.299 0.259 0.291 0.299]\n",
      " [0.298 0.294 0.271 0.303]\n",
      " [0.198 0.199 0.185 0.158]]\n"
     ]
    }
   ],
   "source": [
    "labelsvd = np.argmax(abs(U[:,:true_k]),axis=1)\n",
    "Csvd = confusion_matrix(labels,labelsvd,normalize='pred')\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(Csvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the above confusion matrix that LSA is not doing a good clustering.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonnegative matrix factorization (NMF)\n",
    "\n",
    "Another approach to matrix factorization is to approximate\n",
    "\n",
    "    X \\approx W H \n",
    "    \n",
    "where `W` is tall with `R` columns, `H` is wide with `R` columns, and all elements in `W` and `H` are nonnegative. \n",
    "This is called nonnegative matrix factorization, or NMF.\n",
    "The approximation is constructed to minimize the RSS of the approximation error, X-W H.\n",
    "Although this is a non-convex problem, there are good solvers, such as the one supplied in sklearn.\n",
    "\n",
    "The main difference betwen NMF and LSA (where `X \\approx A Vt`) is that NMF gives nonnegative factors `W` and `H`, whereas LSA gives factors with positive and negative values.  Thus, the outputs of NMF are clearly interpretable: the values in the `i`th row vector `W[i,:]` show the strength of the `i`th document across the `R` topics. Likewise, the values in the `j`th column vector `H[:,j]` show the importance of the `j`th term across the `R` topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/schniter.1/anaconda3/envs/default/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 38777)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.decomposition\n",
    "\n",
    "n_nmf = true_k\n",
    "nmf = sklearn.decomposition.NMF(n_components=n_nmf, random_state=1)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_\n",
    "H.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the top terms in each of the NMF term components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF 0: god jesus people believe bible christian don religion edu com\n",
      "NMF 1: graphics image thanks file files format program gif images ftp\n",
      "NMF 2: space nasa edu shuttle orbit launch moon writes earth article\n",
      "NMF 3: objective morality moral edu livesey frank writes keith cobb values\n"
     ]
    }
   ],
   "source": [
    "H_sort = H.argsort()[:, ::-1]\n",
    "for k in range(n_nmf):\n",
    "    print(\"NMF %d:\" % k, end='')\n",
    "    for ind in H_sort[k, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitatively, we can see that NMF does a decent job of clustering the religious terms, graphics terms, and space terms together.\n",
    "In fact, it seemed to be able to discern `alt.atheism` terms like `morality`, `moral`, `think`, `objective` from the `talk.religion.misc` terms like `god`, `jesus`, `christian`, `bible`.\n",
    "\n",
    "To get a more quantitative view, we can do hard document clustering by assigning the `i`th document to the index in `W[i,:]` with the largest value.  One we have clustered all of the documents, we can compute the confusion matrix, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.508 0.012 0.043 0.653]\n",
      " [0.014 0.926 0.047 0.035]\n",
      " [0.012 0.047 0.85  0.04 ]\n",
      " [0.467 0.016 0.059 0.273]]\n"
     ]
    }
   ],
   "source": [
    "labelnmf = np.argmax(W,axis=1)\n",
    "Cnmf = confusion_matrix(labels,labelnmf,normalize='pred')\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(Cnmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, we see that NMF did a good job of clustering the `comp.graphics` and `sci.space` posts.  The posts from `alt.atheism` and `talk.religion.misc` were mixed together in the first and last clusters, which is not surprising the overlap between these topics.  But NMF did a better job of separating them than k-means did: the last NMF cluster is about 2/3 populated with `alt.atheism`.  Also, remember that k-means produced one cluster that didn't correspond to any newsgroup topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "574px",
    "left": "844px",
    "right": "-19px",
    "top": "58px",
    "width": "378px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
