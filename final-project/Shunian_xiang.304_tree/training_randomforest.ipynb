{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff53581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf4b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "Xtr_loadpath = 'Xtr.csv'\n",
    "Xts_loadpath = 'Xts.csv'\n",
    "ytr_loadpath = 'ytr.csv'\n",
    "\n",
    "Xtr = np.loadtxt(Xtr_loadpath, delimiter=\",\")\n",
    "Xts = np.loadtxt(Xts_loadpath, delimiter=\",\")\n",
    "ytr = np.loadtxt(ytr_loadpath, delimiter=\",\")\n",
    "# standardize the training data\n",
    "scaler = StandardScaler()\n",
    "Xtr_standardized = scaler.fit_transform(Xtr)\n",
    "Xts_standardized = scaler.transform(Xts)\n",
    "\n",
    "# save the standardized training data\n",
    "Xtr_savepath = 'Xtr_standardized.csv'\n",
    "Xts_savepath = 'Xts_standardized.csv'\n",
    "ytr_savepath = 'ytr.csv'\n",
    "\n",
    "# save the standardized training data\n",
    "Xtr_savepath = 'Xtr_standardized.csv'\n",
    "Xts_savepath = 'Xts_standardized.csv'\n",
    "ytr_savepath = 'ytr.csv'\n",
    "yts_hat_savepath = 'yts_hat_RF.csv'\n",
    "\n",
    "np.savetxt(Xtr_savepath, Xtr_standardized, delimiter=\",\")\n",
    "np.savetxt(ytr_savepath, ytr, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4b4049a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create regressor object\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    " \n",
    "# Fit the algorithm on the data\n",
    "regressor.fit(Xtr_standardized,ytr)\n",
    "  \n",
    "regressor.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd5b9e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training R2:  0.9262031818673279\n",
      "cross-validation R^2 = 0.434714\n"
     ]
    }
   ],
   "source": [
    "# Get training R2 and testing R2  \n",
    "# Training set R2:\n",
    "r2 = r2_score(ytr,regressor.predict(Xtr_standardized))\n",
    "print('training R2: ',r2)\n",
    "# 5-fold cross validation R2 for these parameters\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=0)\n",
    "scores = cross_val_score(regressor, Xtr_standardized, ytr, cv=kf, scoring='r2')\n",
    "rsq_cv = np.mean(scores)\n",
    "print(\"cross-validation R^2 = %f\" % rsq_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12220cb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04581799, 0.02862986, 0.17030439, 0.0273833 , 0.02744233,\n",
       "       0.02988117, 0.05631938, 0.02899558, 0.03279808, 0.02734625,\n",
       "       0.04012237, 0.04117503, 0.02889334, 0.02963665, 0.03299408,\n",
       "       0.02880184, 0.02971115, 0.0303794 , 0.02595213, 0.0272026 ,\n",
       "       0.03104661, 0.03680931, 0.0377986 , 0.02509774, 0.04165201,\n",
       "       0.03780883])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16134152",
   "metadata": {},
   "source": [
    "### Tune parameters of bootstrap, max_depth, max_features, min_samples_leaf, min_samples_split, n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ad6b8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Best parameters: {'bootstrap': True, 'max_depth': 100, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 300}\n",
      "Highest R2:  0.38890267869124395\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "regressor = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = regressor, param_grid = param_grid, scoring='r2', \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search .fit(Xtr_standardized, ytr)\n",
    "print(\"Best parameters:\",grid_search.best_params_)\n",
    "print(\"Highest R2: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53becec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>R2 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>0.379042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.380059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.380790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.370186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.373300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.367333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.367504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>0.361922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>300</td>\n",
       "      <td>0.360515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.362122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bootstrap  max_depth  max_features  min_samples_leaf  min_samples_split  \\\n",
       "0         True         80             2                 3                  8   \n",
       "1         True         80             2                 3                  8   \n",
       "2         True         80             2                 3                  8   \n",
       "3         True         80             2                 3                 10   \n",
       "4         True         80             2                 3                 10   \n",
       "..         ...        ...           ...               ...                ...   \n",
       "211       True        110             3                 5                 10   \n",
       "212       True        110             3                 5                 10   \n",
       "213       True        110             3                 5                 12   \n",
       "214       True        110             3                 5                 12   \n",
       "215       True        110             3                 5                 12   \n",
       "\n",
       "     n_estimators  R2 score  \n",
       "0             200  0.379042  \n",
       "1             300  0.380059  \n",
       "2            1000  0.380790  \n",
       "3             200  0.370186  \n",
       "4             300  0.373300  \n",
       "..            ...       ...  \n",
       "211           300  0.367333  \n",
       "212          1000  0.367504  \n",
       "213           200  0.361922  \n",
       "214           300  0.360515  \n",
       "215          1000  0.362122  \n",
       "\n",
       "[216 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1 = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"R2 score\"])],axis=1)\n",
    "table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd4e3776",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(bootstrap=True, max_depth=10, max_features=3, min_samples_leaf=1, min_samples_split= 5, n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0e98184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training R2:  0.867497151587342\n",
      "cross-validation R^2 = 0.456493\n"
     ]
    }
   ],
   "source": [
    "# Fit the algorithm on the data\n",
    "regressor.fit(Xtr_standardized,ytr)\n",
    "# Get training R2 and testing R2  \n",
    "# Training set R2:\n",
    "r2 = r2_score(ytr,regressor.predict(Xtr_standardized))\n",
    "print('training R2: ',r2)\n",
    "# 5-fold cross validation R2 for these parameters\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=0)\n",
    "scores = cross_val_score(regressor, Xtr_standardized, ytr, cv=kf, scoring='r2')\n",
    "rsq_cv = np.mean(scores)\n",
    "print(\"cross-validation R^2 = %f\" % rsq_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d7b563f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Best parameters: {'max_depth': 15, 'min_samples_split': 3, 'n_estimators': 500}\n",
      "Highest R2:  0.4012207397528469\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid2 = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [3,5,8],\n",
    "    'n_estimators': [300,500]\n",
    "}\n",
    "# Create a based model\n",
    "regressor = RandomForestRegressor(bootstrap=True, min_samples_leaf=1, max_features=3)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = regressor, param_grid = param_grid2, scoring='r2', \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search .fit(Xtr_standardized, ytr)\n",
    "print(\"Best parameters:\",grid_search.best_params_)\n",
    "print(\"Highest R2: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bce56cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training R2:  0.9307226855091405\n",
      "cross-validation R^2 = 0.472775\n"
     ]
    }
   ],
   "source": [
    "# Fit the algorithm on the data\n",
    "regressor.fit(Xtr_standardized,ytr)\n",
    "# Get training R2 and testing R2  \n",
    "# Training set R2:\n",
    "r2 = r2_score(ytr,regressor.predict(Xtr_standardized))\n",
    "print('training R2: ',r2)\n",
    "# 5-fold cross validation R2 for these parameters\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=0)\n",
    "scores = cross_val_score(regressor, Xtr_standardized, ytr, cv=kf, scoring='r2')\n",
    "rsq_cv = np.mean(scores)\n",
    "print(\"cross-validation R^2 = %f\" % rsq_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "828afd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1342, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\xiang\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.40252223 0.40321222 0.39761208 0.3990303\n",
      "        nan        nan 0.42613129 0.42964957 0.42401895 0.42582807\n",
      "        nan        nan 0.43272464 0.43512886 0.43076358 0.42914552\n",
      "        nan        nan 0.4340401  0.43555788 0.42982137 0.4305415\n",
      "        nan        nan 0.43590512 0.43534197 0.43004168 0.43159607]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 100, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Highest R2:  0.43590511740508336\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid3 = {\n",
    "    'max_depth': [15,20,25,30,100],\n",
    "    'min_samples_split': [1,2,3],\n",
    "    'n_estimators': [500,800]\n",
    "}\n",
    "# Create a based model\n",
    "regressor = RandomForestRegressor(bootstrap=True, min_samples_leaf=1, max_features=3)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = regressor, param_grid = param_grid3, scoring='r2', \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search .fit(Xtr_standardized, ytr)\n",
    "print(\"Best parameters:\",grid_search.best_params_)\n",
    "print(\"Highest R2: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5c6edd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>R2 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.402522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>0.403212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.397612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "      <td>0.399030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.426131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>0.429650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.424019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "      <td>0.425828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.432725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>0.435129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.430764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "      <td>0.429146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.434040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>0.435558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.429821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "      <td>0.430542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.435905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>0.435342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.430042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "      <td>0.431596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_split  n_estimators  R2 score\n",
       "0          15                  1           500       NaN\n",
       "1          15                  1           800       NaN\n",
       "2          15                  2           500  0.402522\n",
       "3          15                  2           800  0.403212\n",
       "4          15                  3           500  0.397612\n",
       "5          15                  3           800  0.399030\n",
       "6          20                  1           500       NaN\n",
       "7          20                  1           800       NaN\n",
       "8          20                  2           500  0.426131\n",
       "9          20                  2           800  0.429650\n",
       "10         20                  3           500  0.424019\n",
       "11         20                  3           800  0.425828\n",
       "12         25                  1           500       NaN\n",
       "13         25                  1           800       NaN\n",
       "14         25                  2           500  0.432725\n",
       "15         25                  2           800  0.435129\n",
       "16         25                  3           500  0.430764\n",
       "17         25                  3           800  0.429146\n",
       "18         30                  1           500       NaN\n",
       "19         30                  1           800       NaN\n",
       "20         30                  2           500  0.434040\n",
       "21         30                  2           800  0.435558\n",
       "22         30                  3           500  0.429821\n",
       "23         30                  3           800  0.430542\n",
       "24        100                  1           500       NaN\n",
       "25        100                  1           800       NaN\n",
       "26        100                  2           500  0.435905\n",
       "27        100                  2           800  0.435342\n",
       "28        100                  3           500  0.430042\n",
       "29        100                  3           800  0.431596"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"R2 score\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e176c896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training R2:  0.9334310165639778\n",
      "cross-validation R^2 = 0.475371\n"
     ]
    }
   ],
   "source": [
    "regressor.set_params(max_depth=100, min_samples_split=2, n_estimators=500)\n",
    "# Fit the algorithm on the data\n",
    "regressor.fit(Xtr_standardized,ytr)\n",
    "# Get training R2 and testing R2  \n",
    "# Training set R2:\n",
    "r2 = r2_score(ytr,regressor.predict(Xtr_standardized))\n",
    "print('training R2: ',r2)\n",
    "# 5-fold cross validation R2 for these parameters\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=0)\n",
    "scores = cross_val_score(regressor, Xtr_standardized, ytr, cv=kf, scoring='r2')\n",
    "rsq_cv = np.mean(scores)\n",
    "print(\"cross-validation R^2 = %f\" % rsq_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00a030b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model: you must use the .json format for xgboost models!\n",
    "# save the model: you must use the .bz2 format for sklearn models!\n",
    "model_savepath = 'model_RF.bz2'\n",
    "with bz2.BZ2File(model_savepath, 'w') as f:\n",
    "    pickle.dump(regressor,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "670f4b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training R2 =  0.9334310165639778\n",
      "test target predictions saved in yts_hat_xgboost_RF.csv\n"
     ]
    }
   ],
   "source": [
    "# generate kaggle submission file using the validation script\n",
    "!python {\"validation.py \" + model_savepath + \" --Xts_path \" + Xts_savepath + \" --Xtr_path \" + Xtr_savepath + \" --yts_hat_path \" + yts_hat_savepath }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1845a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
