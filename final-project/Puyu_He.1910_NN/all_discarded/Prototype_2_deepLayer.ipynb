{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b46637-09dd-4e48-846b-7a49ceb4af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import r2_score\n",
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78dacaf1-6868-4ae5-befd-a1d4668bf8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "Xtr_loadpath = 'Xtr.csv'\n",
    "Xts_loadpath = 'Xts.csv'\n",
    "ytr_loadpath = 'ytr.csv'\n",
    "\n",
    "Xtr = np.loadtxt(Xtr_loadpath, delimiter=\",\")\n",
    "Xts = np.loadtxt(Xts_loadpath, delimiter=\",\")\n",
    "ytr = np.loadtxt(ytr_loadpath, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae45109c-c2ca-4718-869e-276b7140fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the training data\n",
    "Xtr_mean = np.mean(Xtr,axis=0)\n",
    "Xtr_std = np.std(Xtr,axis=0)\n",
    "ytr_mean = np.mean(ytr)\n",
    "ytr_std = np.std(ytr)\n",
    "\n",
    "Xtr_standardized = ((Xtr-Xtr_mean[None,:])/Xtr_std[None,:]) # revise this line as needed\n",
    "Xts_standardized = ((Xts-Xtr_mean[None,:])/Xtr_std[None,:]) # revise this line as needed\n",
    "ytr_standardized = ((ytr-ytr_mean)/ytr_std)\n",
    "\n",
    "# save the standardized training data\n",
    "Xtr_savepath = 'Xtr_pytorch.csv'\n",
    "Xts_savepath = 'Xts_pytorch.csv'\n",
    "ytr_savepath = 'ytr_pytorch.csv'\n",
    "yts_hat_savepath = 'yts_hat_pytorch.csv'\n",
    "\n",
    "np.savetxt(Xtr_savepath, Xtr_standardized, delimiter=\",\")\n",
    "np.savetxt(Xts_savepath, Xts_standardized, delimiter=\",\")\n",
    "np.savetxt(ytr_savepath, ytr_standardized, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22b1cbed-ee8a-4089-9372-b214cff5f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy arrays to PyTorch tensors\n",
    "Xtr_torch = torch.Tensor(Xtr_standardized)\n",
    "ytr_torch = torch.Tensor(ytr)\n",
    "\n",
    "batch_size = 100  # size of each batch\n",
    "\n",
    "# Create a training Dataset\n",
    "train_ds = torch.utils.data.TensorDataset(Xtr_torch, ytr_torch)\n",
    "# Creates a training DataLoader from this Dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a849753-8c0d-4901-9610-8127d3a23261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=26, out_features=2187, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=2187, out_features=1262, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=1262, out_features=729, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.5, inplace=False)\n",
      "  (9): Linear(in_features=729, out_features=420, bias=True)\n",
      "  (10): ReLU()\n",
      "  (11): Dropout(p=0.5, inplace=False)\n",
      "  (12): Linear(in_features=420, out_features=243, bias=True)\n",
      "  (13): ReLU()\n",
      "  (14): Dropout(p=0.5, inplace=False)\n",
      "  (15): Linear(in_features=243, out_features=81, bias=True)\n",
      "  (16): ReLU()\n",
      "  (17): Dropout(p=0.5, inplace=False)\n",
      "  (18): Linear(in_features=81, out_features=27, bias=True)\n",
      "  (19): ReLU()\n",
      "  (20): Linear(in_features=27, out_features=9, bias=True)\n",
      "  (21): ReLU()\n",
      "  (22): Linear(in_features=9, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "nin = Xtr.shape[1]\n",
    "nout = 1\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(nin, 128*5),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.5),  # Add dropout layer with probability 0.2\n",
    "#     nn.Linear(128*5, 64*5),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.5),  # Add dropout layer with probability 0.2\n",
    "#     nn.Linear(64*5, 32*5),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.5),  # Add dropout layer with probability 0.2\n",
    "#     nn.Linear(32*5, 16*5),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.5),  # Add dropout layer with probability 0.2\n",
    "#     nn.Linear(16*5, 8*5),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(8*5, 4*5),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(4*5, 2*5),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(2*5, nout)\n",
    "# )\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(nin, 2187),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),  # Add dropout layer with probability 0.2\n",
    "    nn.Linear(2187, 1262),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),  # Add dropout layer with probability 0.2\n",
    "    nn.Linear(1262, 729),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),  # Add dropout layer with probability 0.2\n",
    "    nn.Linear(729, 420),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),  # Add dropout layer with probability 0.2   \n",
    "    nn.Linear(420, 243),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),  # Add dropout layer with probability 0.2  \n",
    "    nn.Linear(243, 81),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),  # Add dropout layer with probability 0.2\n",
    "    nn.Linear(81, 27),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(27, 9),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(9, nout)\n",
    ")\n",
    "\n",
    "print(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f6e190-eefa-4e65-9755-9766c0ac95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the optimizer and loss function\n",
    "\n",
    "epochs = 500\n",
    "lrate = 2.5e-6\n",
    "decay = lrate/epochs\n",
    "lambda1 = lambda epoch: (1-decay)*epoch\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=lrate)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(opt, lr_lambda=lambda1)\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.HuberLoss(reduction='mean', delta=30)\n",
    "#criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a53724c-0242-47c5-b0c1-7bfba9c13c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10   Train Loss: 96.995   R^2: 0.021   \n",
      "Epoch: 20   Train Loss: 80.334   R^2: 0.200   \n",
      "Epoch: 30   Train Loss: 77.121   R^2: 0.227   \n",
      "Epoch: 40   Train Loss: 72.808   R^2: 0.272   \n",
      "Epoch: 50   Train Loss: 67.628   R^2: 0.305   \n",
      "Epoch: 60   Train Loss: 65.758   R^2: 0.327   \n",
      "Epoch: 70   Train Loss: 61.508   R^2: 0.368   \n",
      "Epoch: 80   Train Loss: 59.505   R^2: 0.396   \n",
      "Epoch: 90   Train Loss: 56.866   R^2: 0.417   \n",
      "Epoch: 100   Train Loss: 52.859   R^2: 0.424   \n",
      "Epoch: 110   Train Loss: 51.430   R^2: 0.475   \n",
      "Epoch: 120   Train Loss: 49.020   R^2: 0.477   \n",
      "Epoch: 130   Train Loss: 47.625   R^2: 0.497   \n",
      "Epoch: 140   Train Loss: 43.506   R^2: 0.543   \n",
      "Epoch: 150   Train Loss: 42.231   R^2: 0.557   \n",
      "Epoch: 160   Train Loss: 42.047   R^2: 0.562   \n",
      "Epoch: 170   Train Loss: 39.524   R^2: 0.576   \n",
      "Epoch: 180   Train Loss: 40.740   R^2: 0.577   \n",
      "Epoch: 190   Train Loss: 39.740   R^2: 0.568   \n",
      "Epoch: 200   Train Loss: 39.350   R^2: 0.579   \n",
      "Epoch: 210   Train Loss: 38.747   R^2: 0.588   \n",
      "Epoch: 220   Train Loss: 36.443   R^2: 0.608   \n",
      "Epoch: 230   Train Loss: 36.510   R^2: 0.610   \n",
      "Epoch: 240   Train Loss: 34.448   R^2: 0.638   \n",
      "Epoch: 250   Train Loss: 34.753   R^2: 0.627   \n",
      "Epoch: 260   Train Loss: 36.318   R^2: 0.623   \n",
      "Epoch: 270   Train Loss: 35.029   R^2: 0.630   \n",
      "Epoch: 280   Train Loss: 33.316   R^2: 0.640   \n",
      "Epoch: 290   Train Loss: 33.792   R^2: 0.646   \n",
      "Epoch: 300   Train Loss: 34.887   R^2: 0.635   \n",
      "Epoch: 310   Train Loss: 32.219   R^2: 0.661   \n",
      "Epoch: 320   Train Loss: 33.975   R^2: 0.647   \n",
      "Epoch: 330   Train Loss: 33.467   R^2: 0.646   \n",
      "Epoch: 340   Train Loss: 34.541   R^2: 0.635   \n",
      "Epoch: 350   Train Loss: 33.889   R^2: 0.643   \n",
      "Epoch: 360   Train Loss: 31.739   R^2: 0.673   \n",
      "Epoch: 370   Train Loss: 31.981   R^2: 0.659   \n",
      "Epoch: 380   Train Loss: 31.580   R^2: 0.678   \n",
      "Epoch: 390   Train Loss: 32.409   R^2: 0.663   \n",
      "Epoch: 400   Train Loss: 31.269   R^2: 0.673   \n",
      "Epoch: 410   Train Loss: 32.229   R^2: 0.654   \n",
      "Epoch: 420   Train Loss: 34.827   R^2: 0.633   \n",
      "Epoch: 430   Train Loss: 33.051   R^2: 0.646   \n",
      "Epoch: 440   Train Loss: 31.934   R^2: 0.656   \n",
      "Epoch: 450   Train Loss: 31.702   R^2: 0.664   \n",
      "Epoch: 460   Train Loss: 32.441   R^2: 0.659   \n",
      "Epoch: 470   Train Loss: 37.595   R^2: 0.616   \n",
      "Epoch: 480   Train Loss: 35.707   R^2: 0.626   \n",
      "Epoch: 490   Train Loss: 35.788   R^2: 0.626   \n",
      "Epoch: 500   Train Loss: 33.642   R^2: 0.642   \n",
      "Epoch: 510   Train Loss: 34.705   R^2: 0.619   \n",
      "Epoch: 520   Train Loss: 34.485   R^2: 0.632   \n",
      "Epoch: 530   Train Loss: 34.680   R^2: 0.640   \n",
      "Epoch: 540   Train Loss: 32.988   R^2: 0.657   \n",
      "Epoch: 550   Train Loss: 33.821   R^2: 0.645   \n",
      "Epoch: 560   Train Loss: 35.497   R^2: 0.631   \n",
      "Epoch: 570   Train Loss: 34.335   R^2: 0.640   \n",
      "Epoch: 580   Train Loss: 38.952   R^2: 0.604   \n",
      "Epoch: 590   Train Loss: 33.597   R^2: 0.628   \n",
      "Epoch: 600   Train Loss: 36.356   R^2: 0.616   \n",
      "Epoch: 610   Train Loss: 35.912   R^2: 0.625   \n",
      "Epoch: 620   Train Loss: 45.019   R^2: 0.532   \n",
      "Epoch: 630   Train Loss: 42.515   R^2: 0.544   \n",
      "Epoch: 640   Train Loss: 40.807   R^2: 0.583   \n",
      "Epoch: 650   Train Loss: 47.001   R^2: 0.500   \n",
      "Epoch: 660   Train Loss: 45.437   R^2: 0.531   \n",
      "Epoch: 670   Train Loss: 44.485   R^2: 0.530   \n",
      "Epoch: 680   Train Loss: 42.874   R^2: 0.544   \n",
      "Epoch: 690   Train Loss: 45.859   R^2: 0.515   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17244\\806416831.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# Compute gradients using back propagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;31m# Take an optimization 'step'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "num_epoch = epochs\n",
    "\n",
    "a_tr_loss = np.zeros([num_epoch])\n",
    "a_tr_Rsq = np.zeros([num_epoch])\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "\n",
    "    model.train() # put model in training mode\n",
    "    batch_loss_tr = []\n",
    "    batch_Rsq_tr = []\n",
    "    # iterate over training set\n",
    "    for train_iter, data in enumerate(train_loader):\n",
    "        x_batch,y_batch = data\n",
    "        \n",
    "        y_batch = y_batch.view(-1,1)\n",
    "        #y_batch = y_batch.type(torch.long)\n",
    "        \n",
    "        out = model(x_batch)\n",
    "        # Compute Loss\n",
    "        loss = criterion(out,y_batch.type(torch.float))\n",
    "        batch_loss_tr.append(loss.item())\n",
    "        # Compute R-square\n",
    "        Rsq = r2_score(y_batch.type(torch.float).detach().numpy(), out.detach().numpy())\n",
    "        batch_Rsq_tr.append(Rsq.item())\n",
    "        # Compute gradients using back propagation\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        # Take an optimization 'step'\n",
    "        opt.step()\n",
    "        \n",
    "    # Take scheduler step\n",
    "    scheduler.step()\n",
    "        \n",
    "    a_tr_loss[epoch] = np.mean(batch_loss_tr) # Compute average loss over epoch\n",
    "    a_tr_Rsq[epoch] = np.mean(batch_Rsq_tr)\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Epoch: {0:2d}   Train Loss: {1:.3f}   '.format(epoch+1, a_tr_loss[epoch])\n",
    "             + 'R^2: {0:.3f}   '.format(a_tr_Rsq[epoch])\n",
    "             )\n",
    "    \n",
    "with torch.no_grad():\n",
    "    predict = model(torch.Tensor(Xtr_standardized)).detach().numpy().ravel()\n",
    "\n",
    "r2 = r2_score(ytr,predict)\n",
    "print('training R2: ',r2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286cf170-2380-4782-8ebe-a4d8d925b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = len(a_tr_Rsq)\n",
    "plt.plot(np.arange(1,nepochs+1), a_tr_Rsq, 'o-', linewidth=1)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318343c0-4316-466a-b376-c8ecf89b262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = len(a_tr_loss)\n",
    "ntr = Xtr.shape[0]\n",
    "epochs = np.arange(1,nsteps+1)*batch_size/ntr\n",
    "plt.semilogy(epochs, a_tr_loss)\n",
    "plt.xlabel('Epochs', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.grid()\n",
    "plt.xlim([0,np.max(epochs)])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471376b7-d8f2-47e1-944e-89f48bad2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model: you must use the .pth format for pytorch models!\n",
    "model_savepath = 'model.pth'\n",
    "\n",
    "# To save a PyTorch model, we first pass an input through the model, \n",
    "# and then save the \"trace\". \n",
    "# For this purpose, we can use any input. \n",
    "# We will create a random input with the proper dimension.\n",
    "x = torch.randn(26) # random input\n",
    "x = x[None,:] # add singleton batch index\n",
    "with torch.no_grad():\n",
    "    traced_cell = torch.jit.trace(model, (x))\n",
    "\n",
    "# Now we save the trace\n",
    "torch.jit.save(traced_cell, model_savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a961efc-47e6-4757-9bcb-3d590aa865e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate kaggle submission file using the validation script\n",
    "!python {\"validation.py \" + model_savepath + \" --Xts_path \" + Xts_savepath + \" --Xtr_path \" + Xtr_savepath + \" --yts_hat_path \" + yts_hat_savepath } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba3c3a-aef0-441f-92dc-3c48da1b5937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
